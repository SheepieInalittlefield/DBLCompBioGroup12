{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ ME\n",
    "\n",
    "This file contains the main code for encoding and decoding digital information to and from DNA. Two additional files are needed for running it. (utilities.py and checked_seedlist.txt) This second file must be unpacked from the .rar file to .txt in your working directory. In case this unpacking does not work the code can be adjusted slightly at the cost of speed. For this two lines in the Encode funtion have to be uncommented and 3 other lines have to be removed. Further info is commented in the function. \n",
    "\n",
    "Certain pieces of code have been copied and adjusted\n",
    "- about palindromes: https://www.geeksforgeeks.org/find-number-distinct-palindromic-sub-strings-given-string/\n",
    "- def sim_seq_simple: our mentor \n",
    "- Linear Feedback Shift Register (LFSR) used for generating the seedlist: Erlich et al. https://github.com/TeamErlich/dna-fountain/blob/master/lfsr.py\n",
    "\n",
    "The reedsolo library can be installed running the following in the windows command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade reedsolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utilities as util\n",
    "import os\n",
    "import reedsolo\n",
    "import random\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET GLOBAL VARIABLES\n",
    "max_homopolymer = 3                     # maximum allowed homopolymer length\n",
    "cg_content = (0.45,0.55)                # range (tuple) for allowed CG-content\n",
    "ecc_bytes = 4                           # number of error correcting code bytes per droplet\n",
    "robust_soliton_para = (0.001, 0.025)    # parameters of Robust Soliton (c and delta)\n",
    "loss_of_droplets = 0.06                 # expected percentage of droplets lost during synthesis simulation\n",
    "correct = True                          # correct faults in recovered droplets boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set variables for file names/directory\n",
    "\n",
    "# path to file to be encoded (change this!)\n",
    "path = os.path.abspath('Input Data\\\\Lorem ipsum.txt')\n",
    "\n",
    "# path to decoded file (change this!)\n",
    "decoded_path = os.path.abspath(\"Output Data\\\\Lorem ipsum recovered.txt\")\n",
    "\n",
    "# path to encoded droplet DNA strands (shouldn't need to change)\n",
    "DNA_path = os.path.abspath(\"Temp Data\\\\DNA_strands.txt\")\n",
    "\n",
    "# path to DNA strands resulting from simulation (shouldn't need to change)\n",
    "sequenced_path = os.path.abspath(\"Temp Data\\\\sequenced.txt\")\n",
    "\n",
    "# # filename of recovered file\n",
    "# result_filename = \"recovered.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "\n",
    "structure\n",
    "- read randomize and segment the data\n",
    "- get number of droplets to be made\n",
    "- make enough droplets passing the biochemical requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these cells to encode the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encode(file_path, robust_soliton_para, loss_of_droplets, max_homopolymer, cg_content, ecc_bytes) -> list:\n",
    "    \"\"\" Read and encode a file using the luby transform, returning a list of DNA sequences\n",
    "    INPUT:\n",
    "        file_path: path to the file to be encoded\n",
    "        robust_soliton_para: parameters c and delta for the soliton distibution\n",
    "        loss_of_droplets: expected loss of droplets in synthesis simulation\n",
    "        max_homopolymer: maximum length of homopolymer sequences allowed\n",
    "        cg_content: tuple of minimum and maximum CG content allowed\n",
    "        ecc_bytes: number of error correcting bytes per droplet\n",
    "    OUTPUT:\n",
    "        droplets: list of DNA sequences\n",
    "        info: contains total segments, redundancy, number of generated droplets, number of accepted droplets\n",
    "    \"\"\"\n",
    "    # read, randomize and segment original file to binary segments\n",
    "    data = util.OpenFile(file_path)\n",
    "    data = bytearray(data)\n",
    "    randomise_seed = math.ceil(len(data)/32)\n",
    "    data = util.RandomizeMessage(data, randomise_seed)\n",
    "    data = util.Bytearray2Binary(data)\n",
    "    data = util.Segment(data)\n",
    "    data_bytearray = [util.Binary2Bytearray(segment) for segment in data]\n",
    "    \n",
    "    # calculate number of droplets to be made\n",
    "    total_segments = len(data)\n",
    "    redundancy = util.RobustSoliton(total_segments, robust_soliton_para, True)/(1-loss_of_droplets)\n",
    "    droplets_required = int(redundancy*total_segments)\n",
    "    \n",
    "    # initiate lfsr to hop through possible seeds.\n",
    "    with open(\"checked_seedlist.txt\" , \"r\") as f:\n",
    "        seedlist = f.read().splitlines()\n",
    "#     seeds_lfsr = util.LFSR() #use if checked_seedlist.txt is not available and remove two lines prior\n",
    "       \n",
    "    # calculate probabilities of number of segments in a droplet\n",
    "    nr_droplets_probablities = util.RobustSoliton(total_segments, robust_soliton_para)\n",
    "    \n",
    "    # make droplets\n",
    "    droplets = []\n",
    "    i = 0 \n",
    "    while len(droplets) < droplets_required:\n",
    "        seed = int(seedlist[i])\n",
    "#         seed = next(seeds_lfsr) #use if checked_seedlist.txt is not available and remove one line prior\n",
    "        current_drop = util.MakeDroplet(data_bytearray, seed, nr_droplets_probablities, ecc_bytes)\n",
    "        current_drop = util.Binary2DNA(util.Bytearray2Binary(current_drop))\n",
    "        if util.CheckBiochemicalRequirements(current_drop, max_homopolymer, cg_content):\n",
    "            droplets.append(current_drop)\n",
    "        i+=1\n",
    "    \n",
    "    # make metadatastrands\n",
    "    for x in range(10): # now 10 for adding it in 10 times\n",
    "        metastrand = util.CreateMetaStrand(total_segments,ecc_bytes)\n",
    "        droplets.append(metastrand)\n",
    "    \n",
    "    info = (total_segments, redundancy, i, len(droplets))\n",
    "    return droplets, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "encoded, info = Encode(path, robust_soliton_para, loss_of_droplets, max_homopolymer, cg_content, ecc_bytes)\n",
    "f = open(DNA_path, \"w\")\n",
    "for i in encoded:\n",
    "    f.write(i + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "print(\"The time of encoding is :\", timeit.default_timer() - starttime)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to simulate PCR on the encoded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_seq_simple(sequences, dropout = 0.01, insert_rate = 0.00042, del_rate = 0.00188, sub_rate = 0.00407):\n",
    "    # Takes sequences as a list of unique DNA sequences and simulates: synthesis, PCR and NGS\n",
    "    # Dropout is the dropout rate (i.e. the number of sequences that are not recovered)\n",
    "    # For baselevel errors we have insert_rate for insertions, del_rate for deletions and sub_rate for substitutions.\n",
    "    # Default values for base errors are taken from https://www.nature.com/articles/nbt.4079\n",
    "    s = sequences.copy()\n",
    "    random.shuffle(s)\n",
    "    for _ in range(0, int(dropout*len(s))):\n",
    "        s.pop()\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        seq_l = list(s[i])\n",
    "        mod = 0 # Inserting messes with indexing so we skip over inserted bases using this counter\n",
    "        for base_i in range(len(seq_l)):\n",
    "            mutate_rand = random.random()\n",
    "            if mutate_rand < insert_rate:\n",
    "                # Insert random nucleotide after this base\n",
    "                seq_l.insert(base_i+mod, random.choice(['A','C', 'T', 'G']))\n",
    "                mod+=1\n",
    "            elif mutate_rand > insert_rate and mutate_rand < (del_rate+insert_rate):\n",
    "                # Delete this nucleotide (later)\n",
    "                seq_l[base_i+mod] = '_'\n",
    "            elif mutate_rand > (insert_rate+del_rate) and mutate_rand < (del_rate+insert_rate+sub_rate):\n",
    "                # Substitute base\n",
    "                seq_l[base_i+mod] = random.choice(['A', 'C', 'T', 'G'])\n",
    "        if '_' in seq_l:\n",
    "            for dels in range(seq_l.count('_')):\n",
    "                seq_l.remove('_')\n",
    "        s[i] = ''.join(seq_l)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DNA_path, 'r') as f:\n",
    "    dropletlist = [line.rstrip('\\n') for line in f]\n",
    "sequenced = sim_seq_simple(dropletlist, dropout = 0.001, insert_rate = 0.000042, del_rate = 0.000188, sub_rate = 0.000407)\n",
    "with open(sequenced_path, \"w\") as file:\n",
    "    for i in sequenced:\n",
    "        file.write(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to decode the file, the decoded file will also be compared to the original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "with open(sequenced_path, 'r') as f:\n",
    "    dropletlist = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "\n",
    "# check the length of droplets and select metadata strands \n",
    "metadata = []\n",
    "OKdroplets = []\n",
    "for strand in dropletlist:\n",
    "    if util.CheckOligoLength (strand,length=144+ecc_bytes*4):\n",
    "        if strand[:16] == \"ACGTACGTACGTACGT\":\n",
    "            metadata.append(strand)\n",
    "        else:\n",
    "            OKdroplets.append(strand)\n",
    "\n",
    "# get the total number of segments\n",
    "total_segments_list =[]\n",
    "for metastrand in metadata:\n",
    "    total_segments_list = util.DecodeMetaStrand(metastrand, total_segments_list)\n",
    "total_segments = max(set(total_segments_list), key = total_segments_list.count)\n",
    "\n",
    "# retrieve payload and which segments are in each droplet\n",
    "simplified_droplets = []\n",
    "corrected_droplets = []\n",
    "rsc = reedsolo.RSCodec(ecc_bytes)\n",
    "for strand in OKdroplets:\n",
    "    binary_strand = util.DNA2Binary(strand)\n",
    "    bytearray_strand = util.Binary2Bytearray(binary_strand)\n",
    "    if rsc.check(bytearray_strand)[0]:\n",
    "        droplet_seed = int(binary_strand[0:32], 2)\n",
    "        segment_amount, segment_indices = util.RecoverSeed(droplet_seed, total_segments, robust_soliton_para)\n",
    "        payload = binary_strand[32:288]\n",
    "        simplified_droplets.append((segment_indices, payload))\n",
    "    elif correct:\n",
    "        try:\n",
    "            binary_strand = util.Bytearray2Binary(rsc.decode(bytearray_strand)[0])\n",
    "            droplet_seed = int(binary_strand[0:32], 2)\n",
    "            segment_amount, segment_indices = util.RecoverSeed(droplet_seed, total_segments, robust_soliton_para)\n",
    "            payload = binary_strand[32:288]\n",
    "            corrected_droplets.append((segment_indices, payload))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "simplified_droplets += corrected_droplets\n",
    "\n",
    "print(\"The time of fixing droplets and simplifying droplets is :\", timeit.default_timer() - starttime)\n",
    "print(len(corrected_droplets), len(simplified_droplets), len(dropletlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "output_data = {}\n",
    "input_data = simplified_droplets\n",
    "newsolves = 1\n",
    "while newsolves > 0:\n",
    "    input_data, output_data, newsolves = util.Decode(input_data, output_data)\n",
    "    \n",
    "print(\"The time of decoding simplified droplets is :\", timeit.default_timer() - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_data)==total_segments:\n",
    "    # reconstruct segments to original file\n",
    "    solution = ''.join([output_data[x] for x in range(len(output_data))])\n",
    "    solution = util.RemovePadding(solution)\n",
    "    solution = util.RandomizeMessage(util.Binary2Bytearray(solution),len(output_data))\n",
    "    \n",
    "    # compare reconstructed file to original\n",
    "    file_path = path\n",
    "    data = bytearray(util.OpenFile(file_path))\n",
    "    if data == solution:\n",
    "        print(\"file recovery was 100% succesfull!!\")\n",
    "    else:\n",
    "        bad=0\n",
    "        for x in range(len(solution)):\n",
    "            if solution[x]!=data[x]:\n",
    "                bad+=1\n",
    "        bad/len(solution)\n",
    "        print(\"All segments were solved but contained errors. Mistakes as factor of entire reconstructed file\" + bad/len(solution))\n",
    "else:\n",
    "    solution = bytearray(0)\n",
    "    print(\"Solution could not be reached, increase redundancy. \" + str(len(output_data))+ \" segments were solved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing decoded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(decoded_path, \"wb\") as file:\n",
    "    file.write(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "\n",
    "Graph solved segments vs incoming droplets. For a large number of segments this may take a while\n",
    "\n",
    "input needed is only simplified_droplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {}\n",
    "input_data = []\n",
    "y = []\n",
    "\n",
    "for x in range(len(simplified_droplets)):\n",
    "    input_data.append(simplified_droplets[x])\n",
    "    newsolves = 1\n",
    "    while newsolves > 0:\n",
    "        input_data, output_data, newsolves = util.Decode(input_data, output_data)\n",
    "    y.append(len(output_data))\n",
    "plt.plot(y)\n",
    "plt.xlabel(\"Recieved droplets\")\n",
    "plt.ylabel(\"Solved segments\")\n",
    "plt.title(\"Solved segments during decoding the luby transform\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
