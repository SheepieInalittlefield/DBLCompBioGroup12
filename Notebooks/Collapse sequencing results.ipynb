{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from Bas' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sequenced.txt\", 'r') as f:\n",
    "    dropletlist = [line.rstrip('\\n') for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161680"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dropletlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erlich et al. mention that they only collapse identical sequences. So I will attempt to do that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse(sim_results):\n",
    "    sequences =  {}\n",
    "    for i in sim_results:\n",
    "        if i not in sequences:\n",
    "            sequences[i] = 1 \n",
    "        else: \n",
    "            sequences[i] += 1 \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed = collapse(dropletlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"collapsed.txt\" , \"w\") as file:\n",
    "    for w in sorted(collapsed, key=collapsed.get, reverse=True):\n",
    "        file.write(w + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another idea, that I haven't had time to implement yet, would be to utilize a similarity metric such as the hamming distance to group sequences together, rather than just only putting identical sequences together. This would be much slower, but it would also allow us to retain much more data. currently however, it's possible to recover all segments using the method implemented above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
